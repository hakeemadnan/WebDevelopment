
NLP -

text  collection
text cleaning
tokenization - breaking into smaller units-  tokens
stop words removal
steming - reducing the words to their root form -may not be a real word
lemmatization - converting words to their dictionary forms
bag of words -The Bag of Words (BoW) model is a fundamental technique in Natural Language Processing (NLP) used to convert text into numerical data. This model is essential because machine learning algorithms require numerical input, and raw text cannot be directly processed by these algorithms.
Part-of-Speech (POS) tagging in NLP is the process of assigning grammatical categories (like noun, verb, adjective) to each word in a sentence based on its definition and context. It is a classification task that plays a central role in morphological analysis within Natural Language Understanding (NLU) pipelines.

From a linguistic perspective, POS tagging is closely tied to morphology because it involves identifying the grammatical form of words, often using morphological rules such as suffixes (-ed for past tense verbs, -tion for nouns) and inflections (plural forms, verb conjugations) . While it also uses lexical resources (dictionaries) and contextual semantics, its primary model type is morphological.
TF_IDF 
important  words get higher weight and common words get lower weight
widely used for sentiment analysis
mdel building :

n grams in nlp
sequence of n consecutive items taken from a text to capture context and word relationship
n= number of items 
unigram
bigram


Named entity recognition
is a subtask of nlp that identifies and classifies important imformation (entities) in text into predefined categories 

purpose 
information extraction
data structuring 
improving search engines 
question answer system

---
2-part of speech tagging
3feature engineering
4 entity classification

challenges 
ambiguity 
new entities
domain specific entities 
misspellings
low resource languages
